
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Learning Hadoop: WebHdfsFileSystem vs FileSystem - paulcichonski.com</title>
  <meta name="author" content="Paul Cichonski">



<meta name="description" content="Personal blog about whatever I have been thinking about lately, normally focused on software and distributed systems, with a bit of ontology mixed in.">


  
  <meta name="keywords" content="paul cichonski, software, engineering, cassandra, blog, systems theory, distributed systems, octopress" />

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://paulcichonski.com/blog/2014/07/19/learning-hadoop-webhdfsfilesystem-vs-filesystem">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="paulcichonski.com" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/lib/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-45619319-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


  <meta property="og:url" content="http://paulcichonski.com/blog/2014/07/19/learning-hadoop-webhdfsfilesystem-vs-filesystem/">
<meta property="og:type" content="website" />

<meta property="og:title" content="Learning Hadoop: WebHdfsFileSystem vs FileSystem">
<meta property="og:description" content="">
 


</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">paulcichonski.com</a></h1>
  
    <h2>whatever I have been thinking about lately</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:paulcichonski.com" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/about">About</a></li>
   <li><a href="/">Blog</a></li>
   <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      <h1 class="entry-title">Learning Hadoop: WebHdfsFileSystem vs FileSystem</h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-07-19T10:25:00-04:00" pubdate data-updated="true">Jul 19<span>th</span>, 2014</time>
        
      </p>
    
  </header>


<div class="entry-content"><p>For the last few weeks I&rsquo;ve had the chance to start digging into the <a href="http://hadoop.apache.org/">Hadoop</a> ecosystem focusing mainly on
<a href="http://spark.apache.org/">Spark</a> for distributed compute (both batch and streaming) as well as
<a href="http://hadoop.apache.org/docs/r2.4.1/hadoop-project-dist/hadoop-hdfs/HdfsUserGuide.html">HDFS</a> for data storage. The first thing
I noticed is how massive the Hadoop ecosystem. The word <em>Hadoop</em> refers to many different technologies that users
may deploy in many different ways to solve specific Big Data usecases. So referring to <em>Hadoop</em> is similar to referring to phrases
like <em>IT Security</em> in that it very ambiguous until you start digging down into the specifics of the Hadoop deployment.</p>

<p>Enough of the high level speak though, what I really want to talk about is the pain I experienced just trying to get data in and out of
HDFS. Most of the pain was self-inflicted as my mental model going into the problem was induced from over a year working with
<a href="http://cassandra.apache.org/">Cassandra</a>, which is a much simpler system for storing data albeit does not provide as good of a foundation
for storing raw data in a <a href="http://lambda-architecture.net/">lambda architecture</a> type design. In Cassandra you have the cluster and you
have the client, where the client is your application and it speaks to the cluster over the network in a fairly typical client-server model.</p>

<p>I quickly discovered that my <a href="http://en.wikipedia.org/wiki/Map%E2%80%93territory_relation">map was not the territory</a> when I started writing some simple code for sending data into HDFS:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">package</span> <span class="nn">data.generator</span>
</span><span class='line'>
</span><span class='line'><span class="k">import</span> <span class="nn">com.twitter.elephantbird.mapreduce.io.ProtobufBlockWriter</span>
</span><span class='line'><span class="k">import</span> <span class="nn">data.generator.DataUtil.TestMessage</span>
</span><span class='line'><span class="k">import</span> <span class="nn">org.apache.hadoop.conf.Configuration</span>
</span><span class='line'><span class="k">import</span> <span class="nn">org.apache.hadoop.fs.</span><span class="o">{</span><span class="nc">FileSystem</span><span class="o">,</span> <span class="nc">Path</span><span class="o">}</span>
</span><span class='line'><span class="k">import</span> <span class="nn">org.apache.hadoop.io.compress</span>
</span><span class='line'>
</span><span class='line'><span class="k">import</span> <span class="nn">scala.compat.Platform</span>
</span><span class='line'><span class="k">import</span> <span class="nn">scalaz.EphemeralStream</span>
</span><span class='line'>
</span><span class='line'><span class="k">object</span> <span class="nc">DataWriterTest</span> <span class="o">{</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">def</span> <span class="n">main</span><span class="o">(</span><span class="n">args</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">String</span><span class="o">])</span> <span class="o">{</span>
</span><span class='line'>    <span class="n">writeSomeData</span><span class="o">(</span><span class="s">&quot;hdfs://192.168.50.25:50010&quot;</span><span class="o">,</span> <span class="mi">1000000</span><span class="o">,</span> <span class="s">&quot;/tmp/test.snappy&quot;</span><span class="o">)</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">def</span> <span class="n">writeSomeData</span><span class="o">(</span><span class="n">hdfsURI</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">numberOfMessages</span><span class="k">:</span> <span class="kt">Int</span><span class="o">,</span> <span class="n">destPath</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>    <span class="k">def</span> <span class="n">getSnappyWriter</span><span class="o">()</span><span class="k">:</span> <span class="kt">ProtobufBlockWriter</span><span class="o">[</span><span class="kt">TestMessage</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
</span><span class='line'>      <span class="k">val</span> <span class="n">conf</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Configuration</span><span class="o">()</span>
</span><span class='line'>      <span class="k">val</span> <span class="n">fs</span> <span class="k">=</span> <span class="nc">FileSystem</span><span class="o">.</span><span class="n">get</span><span class="o">(</span><span class="k">new</span> <span class="nc">Path</span><span class="o">(</span><span class="n">hdfsURI</span><span class="o">).</span><span class="n">toUri</span><span class="o">,</span> <span class="n">conf</span><span class="o">)</span>
</span><span class='line'>      <span class="k">val</span> <span class="n">outputStream</span> <span class="k">=</span> <span class="n">fs</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="k">new</span> <span class="nc">Path</span><span class="o">(</span><span class="n">destPath</span><span class="o">),</span> <span class="kc">true</span><span class="o">)</span>
</span><span class='line'>      <span class="k">val</span> <span class="n">codec</span> <span class="k">=</span> <span class="k">new</span> <span class="n">compress</span><span class="o">.</span><span class="nc">SnappyCodec</span><span class="o">()</span>
</span><span class='line'>      <span class="n">codec</span><span class="o">.</span><span class="n">setConf</span><span class="o">(</span><span class="n">conf</span><span class="o">);</span>
</span><span class='line'>      <span class="k">val</span> <span class="n">snappyOutputStream</span> <span class="k">=</span> <span class="n">codec</span><span class="o">.</span><span class="n">createOutputStream</span><span class="o">(</span><span class="n">outputStream</span><span class="o">)</span>
</span><span class='line'>      <span class="k">new</span> <span class="nc">ProtobufBlockWriter</span><span class="o">[</span><span class="kt">TestMessage</span><span class="o">](</span><span class="n">snappyOutputStream</span><span class="o">,</span> <span class="n">classOf</span><span class="o">[</span><span class="kt">TestMessage</span><span class="o">])</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'>    <span class="k">def</span> <span class="n">getMessage</span><span class="o">(</span><span class="n">messageId</span><span class="k">:</span> <span class="kt">Long</span><span class="o">)</span><span class="k">:</span> <span class="kt">TestMessage</span> <span class="o">=</span> <span class="nc">DataUtil</span><span class="o">.</span><span class="n">createRandomTestMessage</span><span class="o">(</span><span class="n">messageId</span><span class="o">);</span>
</span><span class='line'>    <span class="c1">// produces a lazy stream of messages</span>
</span><span class='line'>    <span class="k">def</span> <span class="n">getMessageStream</span><span class="o">(</span><span class="n">messageId</span><span class="k">:</span> <span class="kt">Long</span><span class="o">)</span><span class="k">:</span> <span class="kt">EphemeralStream</span><span class="o">[</span><span class="kt">TestMessage</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
</span><span class='line'>      <span class="k">val</span> <span class="n">messageStream</span><span class="k">:</span> <span class="kt">EphemeralStream</span><span class="o">[</span><span class="kt">TestMessage</span><span class="o">]</span> <span class="k">=</span> <span class="n">getMessage</span><span class="o">(</span><span class="n">messageId</span><span class="o">)</span> <span class="o">##::</span> <span class="n">getMessageStream</span><span class="o">(</span><span class="n">messageId</span> <span class="o">+</span> <span class="mi">1</span><span class="o">)</span>
</span><span class='line'>      <span class="k">return</span> <span class="n">messageStream</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">writer</span> <span class="k">=</span> <span class="n">getSnappyWriter</span><span class="o">()</span>
</span><span class='line'>    <span class="n">getMessageStream</span><span class="o">(</span><span class="mi">1</span><span class="o">).</span><span class="n">takeWhile</span><span class="o">(</span><span class="n">message</span> <span class="k">=&gt;</span> <span class="n">message</span><span class="o">.</span><span class="n">getMessageId</span> <span class="o">&lt;</span> <span class="n">numberOfMessages</span><span class="o">)</span>
</span><span class='line'>      <span class="o">.</span><span class="n">foreach</span><span class="o">(</span><span class="n">message</span> <span class="k">=&gt;</span> <span class="n">writer</span><span class="o">.</span><span class="n">write</span><span class="o">(</span><span class="n">message</span><span class="o">))</span>
</span><span class='line'>    <span class="n">writer</span><span class="o">.</span><span class="n">finish</span><span class="o">()</span>
</span><span class='line'>    <span class="n">writer</span><span class="o">.</span><span class="n">close</span><span class="o">()</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>As far as I could tell this pattern for writing was consistent with most of the tutorials I found via Google, the only new thing I added
in was the use of Twitter&rsquo;s <a href="https://github.com/kevinweil/elephant-bird/">elephantbird</a> library to write Snappy compressed Protocol Buffer data.
So I was surprised when I saw (and kept seeing) the following errors:</p>

<p>Client Errors:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>Exception in thread <span class="s2">&quot;main&quot;</span> java.io.IOException: Failed on <span class="nb">local </span>exception: java.io.EOFException; Host Details : <span class="nb">local </span>host is: <span class="s2">&quot;.local/192.168.1.2&quot;</span>; destination host is: <span class="s2">&quot;localhost.localdomain&quot;</span>:50010;
</span><span class='line'>  at org.apache.hadoop.net.NetUtils.wrapException<span class="o">(</span>NetUtils.java:764<span class="o">)</span>
</span><span class='line'>  at org.apache.hadoop.ipc.Client.call<span class="o">(</span>Client.java:1413<span class="o">)</span>
</span><span class='line'>  at org.apache.hadoop.ipc.Client.call<span class="o">(</span>Client.java:1362<span class="o">)</span>
</span><span class='line'>  at org.apache.hadoop.ipc.ProtobufRpcEngine<span class="nv">$Invoker</span>.invoke<span class="o">(</span>ProtobufRpcEngine.java:206<span class="o">)</span>
</span><span class='line'>  at com.sun.proxy.<span class="nv">$Proxy9</span>.create<span class="o">(</span>Unknown Source<span class="o">)</span>
</span><span class='line'>  at sun.reflect.NativeMethodAccessorImpl.invoke0<span class="o">(</span>Native Method<span class="o">)</span>
</span><span class='line'>  at sun.reflect.NativeMethodAccessorImpl.invoke<span class="o">(</span>NativeMethodAccessorImpl.java:57<span class="o">)</span>
</span><span class='line'>  at sun.reflect.DelegatingMethodAccessorImpl.invoke<span class="o">(</span>DelegatingMethodAccessorImpl.java:43<span class="o">)</span>
</span><span class='line'>  at java.lang.reflect.Method.invoke<span class="o">(</span>Method.java:606<span class="o">)</span>
</span><span class='line'>  at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod<span class="o">(</span>RetryInvocationHandler.java:186<span class="o">)</span>
</span><span class='line'>  at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke<span class="o">(</span>RetryInvocationHandler.java:102<span class="o">)</span>
</span><span class='line'>  at com.sun.proxy.<span class="nv">$Proxy9</span>.create<span class="o">(</span>Unknown Source<span class="o">)</span>
</span><span class='line'>  at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create<span class="o">(</span>ClientNamenodeProtocolTranslatorPB.java:258<span class="o">)</span>
</span><span class='line'>  at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate<span class="o">(</span>DFSOutputStream.java:1598<span class="o">)</span>
</span><span class='line'>  at org.apache.hadoop.hdfs.DFSClient.create<span class="o">(</span>DFSClient.java:1460<span class="o">)</span>
</span><span class='line'>  at org.apache.hadoop.hdfs.DFSClient.create<span class="o">(</span>DFSClient.java:1385<span class="o">)</span>
</span><span class='line'>  at org.apache.hadoop.hdfs.DistributedFileSystem<span class="nv">$6</span>.doCall<span class="o">(</span>DistributedFileSystem.java:394<span class="o">)</span>
</span><span class='line'>  at org.apache.hadoop.hdfs.DistributedFileSystem<span class="nv">$6</span>.doCall<span class="o">(</span>DistributedFileSystem.java:390<span class="o">)</span>
</span><span class='line'>  at org.apache.hadoop.fs.FileSystemLinkResolver.resolve<span class="o">(</span>FileSystemLinkResolver.java:81<span class="o">)</span>
</span><span class='line'>  at org.apache.hadoop.hdfs.DistributedFileSystem.create<span class="o">(</span>DistributedFileSystem.java:390<span class="o">)</span>
</span><span class='line'>  at org.apache.hadoop.hdfs.DistributedFileSystem.create<span class="o">(</span>DistributedFileSystem.java:334<span class="o">)</span>
</span><span class='line'>  at org.apache.hadoop.fs.FileSystem.create<span class="o">(</span>FileSystem.java:906<span class="o">)</span>
</span><span class='line'>  at org.apache.hadoop.fs.FileSystem.create<span class="o">(</span>FileSystem.java:887<span class="o">)</span>
</span><span class='line'>  at org.apache.hadoop.fs.FileSystem.create<span class="o">(</span>FileSystem.java:784<span class="o">)</span>
</span><span class='line'>  at data.generator.DataWriterTest<span class="nv">$.</span>getSnappyWriter<span class="nv">$1</span><span class="o">(</span>DataWriterTest.scala:23<span class="o">)</span>
</span><span class='line'>  at data.generator.DataWriterTest<span class="nv">$.</span>writeSomeData<span class="o">(</span>DataWriterTest.scala:35<span class="o">)</span>
</span><span class='line'>  at data.generator.DataWriterTest<span class="nv">$.</span>main<span class="o">(</span>DataWriterTest.scala:16<span class="o">)</span>
</span><span class='line'>  at data.generator.DataWriterTest.main<span class="o">(</span>DataWriterTest.scala<span class="o">)</span>
</span><span class='line'>  at sun.reflect.NativeMethodAccessorImpl.invoke0<span class="o">(</span>Native Method<span class="o">)</span>
</span><span class='line'>  at sun.reflect.NativeMethodAccessorImpl.invoke<span class="o">(</span>NativeMethodAccessorImpl.java:57<span class="o">)</span>
</span><span class='line'>  at sun.reflect.DelegatingMethodAccessorImpl.invoke<span class="o">(</span>DelegatingMethodAccessorImpl.java:43<span class="o">)</span>
</span><span class='line'>  at java.lang.reflect.Method.invoke<span class="o">(</span>Method.java:606<span class="o">)</span>
</span><span class='line'>  at com.intellij.rt.execution.application.AppMain.main<span class="o">(</span>AppMain.java:134<span class="o">)</span>
</span><span class='line'>Caused by: java.io.EOFException
</span><span class='line'>  at java.io.DataInputStream.readInt<span class="o">(</span>DataInputStream.java:392<span class="o">)</span>
</span><span class='line'>  at org.apache.hadoop.ipc.Client<span class="nv">$Connection</span>.receiveRpcResponse<span class="o">(</span>Client.java:1053<span class="o">)</span>
</span><span class='line'>  at org.apache.hadoop.ipc.Client<span class="nv">$Connection</span>.run<span class="o">(</span>Client.java:948<span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>Server Errors (hdfs datanode log):</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: localhost.localdomain:50010:DataXceiver error processing unknown operation  src: /192.168.50.2:56439 dest: /192.168.50.25:50010
</span><span class='line'>java.io.IOException: Version Mismatch <span class="o">(</span>Expected: 28, Received: 26738 <span class="o">)</span>
</span><span class='line'>  at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.readOp<span class="o">(</span>Receiver.java:57<span class="o">)</span>
</span><span class='line'>  at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run<span class="o">(</span>DataXceiver.java:206<span class="o">)</span>
</span><span class='line'>  at java.lang.Thread.run<span class="o">(</span>Thread.java:744<span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>After about 8 hours of lots of googling and ensuring all client and server jars were the same version my surprise turned to frustration. Especially since
the error messages were so vague.</p>

<p>Finally after a few circuits at the gym, I started from scratch and read through all the documentation I could find about typical data loading strategies for HDFS
(something I should have done to begin with). This led me to the realization that my client-server mental model was flawed within the HDFS context
since HDFS makes no assumption about where the data is being written from (in fact it seems to assume that the client is local to the cluster).
Some quick exploration of the <code>org.apache.hadoop.fs.FileSystem</code> class hierarchy showed that there are a variety of different ways for writing
to HDFS and only some of them are over TCP/IP. So with a little refactoring to use the <code>org.apache.hadoop.hdfs.web.WebHdfsFileSystem</code> implementation
my code works just fine:</p>

<p>Note the new <code>webhdfs://</code> protocol in the URI and the new port of <code>50070</code>. There seems to be a tight coupling of protocol to <code>FileSystem</code>
implementation as well as port mapping, but I have not found great documentation yet as to what this coupling is.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'> <span class="k">package</span> <span class="nn">data.generator</span>
</span><span class='line'>
</span><span class='line'> <span class="k">import</span> <span class="nn">java.net.URI</span>
</span><span class='line'>
</span><span class='line'> <span class="k">import</span> <span class="nn">com.twitter.elephantbird.mapreduce.io.ProtobufBlockWriter</span>
</span><span class='line'> <span class="k">import</span> <span class="nn">data.generator.DataUtil.TestMessage</span>
</span><span class='line'> <span class="k">import</span> <span class="nn">org.apache.hadoop.conf.Configuration</span>
</span><span class='line'> <span class="k">import</span> <span class="nn">org.apache.hadoop.fs.</span><span class="o">{</span><span class="nc">FileSystem</span><span class="o">,</span> <span class="nc">Path</span><span class="o">}</span>
</span><span class='line'> <span class="k">import</span> <span class="nn">org.apache.hadoop.hdfs.web.WebHdfsFileSystem</span>
</span><span class='line'> <span class="k">import</span> <span class="nn">org.apache.hadoop.io.compress</span>
</span><span class='line'>
</span><span class='line'> <span class="k">import</span> <span class="nn">scala.compat.Platform</span>
</span><span class='line'> <span class="k">import</span> <span class="nn">scalaz.EphemeralStream</span>
</span><span class='line'>
</span><span class='line'> <span class="k">object</span> <span class="nc">DataWriterTest</span> <span class="o">{</span>
</span><span class='line'>
</span><span class='line'>   <span class="k">def</span> <span class="n">main</span><span class="o">(</span><span class="n">args</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">String</span><span class="o">])</span> <span class="o">{</span>
</span><span class='line'>     <span class="n">writeSomeData</span><span class="o">(</span><span class="s">&quot;webhdfs://192.168.50.25:50070&quot;</span><span class="o">,</span> <span class="mi">1000000</span><span class="o">,</span> <span class="s">&quot;/tmp/test2.snappy&quot;</span><span class="o">)</span>
</span><span class='line'>   <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>   <span class="k">def</span> <span class="n">writeSomeData</span><span class="o">(</span><span class="n">hdfsURI</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">numberOfMessages</span><span class="k">:</span> <span class="kt">Int</span><span class="o">,</span> <span class="n">destPath</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>     <span class="k">def</span> <span class="n">getSnappyWriter</span><span class="o">()</span><span class="k">:</span> <span class="kt">ProtobufBlockWriter</span><span class="o">[</span><span class="kt">TestMessage</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
</span><span class='line'>       <span class="k">val</span> <span class="n">conf</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Configuration</span><span class="o">()</span>
</span><span class='line'>       <span class="k">val</span> <span class="n">fs</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">WebHdfsFileSystem</span><span class="o">();</span>
</span><span class='line'>       <span class="n">fs</span><span class="o">.</span><span class="n">initialize</span><span class="o">(</span><span class="k">new</span> <span class="nc">Path</span><span class="o">(</span><span class="n">hdfsURI</span><span class="o">).</span><span class="n">toUri</span><span class="o">,</span> <span class="n">conf</span><span class="o">)</span>
</span><span class='line'>       <span class="k">val</span> <span class="n">outputStream</span> <span class="k">=</span> <span class="n">fs</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="k">new</span> <span class="nc">Path</span><span class="o">(</span><span class="n">destPath</span><span class="o">),</span> <span class="kc">true</span><span class="o">)</span>
</span><span class='line'>       <span class="k">val</span> <span class="n">codec</span> <span class="k">=</span> <span class="k">new</span> <span class="n">compress</span><span class="o">.</span><span class="nc">SnappyCodec</span><span class="o">()</span>
</span><span class='line'>       <span class="n">codec</span><span class="o">.</span><span class="n">setConf</span><span class="o">(</span><span class="n">conf</span><span class="o">);</span>
</span><span class='line'>       <span class="k">val</span> <span class="n">snappyOutputStream</span> <span class="k">=</span> <span class="n">codec</span><span class="o">.</span><span class="n">createOutputStream</span><span class="o">(</span><span class="n">outputStream</span><span class="o">)</span>
</span><span class='line'>       <span class="k">new</span> <span class="nc">ProtobufBlockWriter</span><span class="o">[</span><span class="kt">TestMessage</span><span class="o">](</span><span class="n">snappyOutputStream</span><span class="o">,</span> <span class="n">classOf</span><span class="o">[</span><span class="kt">TestMessage</span><span class="o">])</span>
</span><span class='line'>     <span class="o">}</span>
</span><span class='line'>     <span class="k">def</span> <span class="n">getMessage</span><span class="o">(</span><span class="n">messageId</span><span class="k">:</span> <span class="kt">Long</span><span class="o">)</span><span class="k">:</span> <span class="kt">TestMessage</span> <span class="o">=</span> <span class="nc">DataUtil</span><span class="o">.</span><span class="n">createRandomTestMessage</span><span class="o">(</span><span class="n">messageId</span><span class="o">);</span>
</span><span class='line'>     <span class="c1">// produces a lazy stream of messages</span>
</span><span class='line'>     <span class="k">def</span> <span class="n">getMessageStream</span><span class="o">(</span><span class="n">messageId</span><span class="k">:</span> <span class="kt">Long</span><span class="o">)</span><span class="k">:</span> <span class="kt">EphemeralStream</span><span class="o">[</span><span class="kt">TestMessage</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
</span><span class='line'>       <span class="k">val</span> <span class="n">messageStream</span><span class="k">:</span> <span class="kt">EphemeralStream</span><span class="o">[</span><span class="kt">TestMessage</span><span class="o">]</span> <span class="k">=</span> <span class="n">getMessage</span><span class="o">(</span><span class="n">messageId</span><span class="o">)</span> <span class="o">##::</span> <span class="n">getMessageStream</span><span class="o">(</span><span class="n">messageId</span> <span class="o">+</span> <span class="mi">1</span><span class="o">)</span>
</span><span class='line'>       <span class="k">return</span> <span class="n">messageStream</span>
</span><span class='line'>     <span class="o">}</span>
</span><span class='line'>     <span class="k">val</span> <span class="n">writer</span> <span class="k">=</span> <span class="n">getSnappyWriter</span><span class="o">()</span>
</span><span class='line'>     <span class="n">getMessageStream</span><span class="o">(</span><span class="mi">1</span><span class="o">).</span><span class="n">takeWhile</span><span class="o">(</span><span class="n">message</span> <span class="k">=&gt;</span> <span class="n">message</span><span class="o">.</span><span class="n">getMessageId</span> <span class="o">&lt;</span> <span class="n">numberOfMessages</span><span class="o">)</span>
</span><span class='line'>       <span class="o">.</span><span class="n">foreach</span><span class="o">(</span><span class="n">message</span> <span class="k">=&gt;</span> <span class="n">writer</span><span class="o">.</span><span class="n">write</span><span class="o">(</span><span class="n">message</span><span class="o">))</span>
</span><span class='line'>     <span class="n">writer</span><span class="o">.</span><span class="n">finish</span><span class="o">()</span>
</span><span class='line'>     <span class="n">writer</span><span class="o">.</span><span class="n">close</span><span class="o">()</span>
</span><span class='line'>   <span class="o">}</span>
</span><span class='line'> <span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p> File in hdfs:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>hdfs dfs -ls -h /tmp
</span><span class='line'>Found 1 item
</span><span class='line'>-rw-r--r--   3 pcichonski supergroup    215.9 M 2014-07-19 08:44 /tmp/test2.snappy
</span></code></pre></td></tr></table></div></figure>


<p>I&rsquo;m still not sure this is the write method for writing large amounts of data to HDFS, but more dots are starting to connect in my head
about how the component parts of the ecosystem fit together. Lots more to learn though.</p>
</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">Paul Cichonski</span></span>

      








  


<time datetime="2014-07-19T10:25:00-04:00" pubdate data-updated="true">Jul 19<span>th</span>, 2014</time>
      

<span class="categories">
  
    <a class='category' href='/blog/categories/hadoop/'>hadoop</a>, <a class='category' href='/blog/categories/hdfs/'>hdfs</a>, <a class='category' href='/blog/categories/scala/'>scala</a>
  
</span>


    </p>
    
      <div class="sharing">
  
  <a href="//twitter.com/share" class="twitter-share-button" data-url="http://paulcichonski.com/blog/2014/07/19/learning-hadoop-webhdfsfilesystem-vs-filesystem/" data-via="paulcichonski" data-counturl="http://paulcichonski.com/blog/2014/07/19/learning-hadoop-webhdfsfilesystem-vs-filesystem/" >Tweet</a>
  
  
  
    <div class="fb-like" data-send="true" data-width="450" data-show-faces="false"></div>
  
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/blog/2014/02/01/recent-talks/" title="Previous Post: Meetup Talks">&laquo; Meetup Talks</a>
      
      
    </p>
  </footer>
</article>

  <section>
    <h1>Comments</h1>
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
  </section>

</div>

<aside class="sidebar">
  
    <section>
  <h1>About Me</h1>
  <p>I'm Paul Cichonski, a software engineer interested in distributed systems, system theory, IT security, andi knowledge representation.</p>
  <div id="about_icons" align="center">
<a href="http://twitter.com/paulcichonski"><img src="/images/twitter.png"
                                             alt="Twitter" /></a>
<a href="http://github.com/paulcichonski"><img src="/images/github.jpeg"
                                             alt="Github" /></a>
<a href="http://www.linkedin.com/in/paulcichonski"><img src="/images/linkedin.png"
                                             alt="Linkedin" /></a>
</div>
</section>
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2014/07/19/learning-hadoop-webhdfsfilesystem-vs-filesystem/">Learning Hadoop: WebHdfsFileSystem vs FileSystem</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/02/01/recent-talks/">Meetup Talks</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/11/10/setting-up-octopress-on-a-new-machine/">Setting Up Octopress on a New Machine</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/11/10/building-this-blog-with-octopress/">Building This Blog With Octopress</a>
      </li>
    
  </ul>
</section>





  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2014 - Paul Cichonski -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'paulcichonski';
      
        
        // var disqus_developer = 1;
        var disqus_identifier = 'http://paulcichonski.com/blog/2014/07/19/learning-hadoop-webhdfsfilesystem-vs-filesystem/';
        var disqus_url = 'http://paulcichonski.com/blog/2014/07/19/learning-hadoop-webhdfsfilesystem-vs-filesystem/';
        var disqus_script = 'embed.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>



<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) {return;}
  js = d.createElement(s); js.id = id; js.async = true;
  js.src = "//connect.facebook.net/en_US/all.js#appId=212934732101925&xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>





  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = '//platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
