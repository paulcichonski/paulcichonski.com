<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[paulcichonski.com]]></title>
  <link href="http://paulcichonski.com/atom.xml" rel="self"/>
  <link href="http://paulcichonski.com/"/>
  <updated>2014-07-19T12:37:20-04:00</updated>
  <id>http://paulcichonski.com/</id>
  <author>
    <name><![CDATA[Paul Cichonski]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Learning Hadoop: WebHdfsFileSystem vs FileSystem]]></title>
    <link href="http://paulcichonski.com/blog/2014/07/19/learning-hadoop-webhdfsfilesystem-vs-filesystem/"/>
    <updated>2014-07-19T10:25:00-04:00</updated>
    <id>http://paulcichonski.com/blog/2014/07/19/learning-hadoop-webhdfsfilesystem-vs-filesystem</id>
    <content type="html"><![CDATA[<p>For the last few weeks I&rsquo;ve had the chance to start digging into the <a href="http://hadoop.apache.org/">Hadoop</a> ecosystem focusing mainly on
<a href="http://spark.apache.org/">Spark</a> for distributed compute (both batch and streaming) as well as
<a href="http://hadoop.apache.org/docs/r2.4.1/hadoop-project-dist/hadoop-hdfs/HdfsUserGuide.html">HDFS</a> for data storage. The first thing
I noticed is how massive the Hadoop ecosystem. The word <em>Hadoop</em> refers to many different technologies that users
may deploy in many different ways to solve specific Big Data usecases. So referring to <em>Hadoop</em> is similar to referring to phrases
like <em>IT Security</em> in that it very ambiguous until you start digging down into the specifics of the Hadoop deployment.</p>

<p>Enough of the high level speak though, what I really want to talk about is the pain I experienced just trying to get data in and out of
HDFS. Most of the pain was self-inflicted as my mental model going into the problem was induced from over a year working with
<a href="http://cassandra.apache.org/">Cassandra</a>, which is a much simpler system for storing data albeit does not provide as good of a foundation
for storing raw data in a <a href="http://lambda-architecture.net/">lambda architecture</a> type design. In Cassandra you have the cluster and you
have the client, where the client is your application and it speaks to the cluster over the network in a fairly typical client-server model.</p>

<p>I quickly discovered that my <a href="http://en.wikipedia.org/wiki/Map%E2%80%93territory_relation">map was not the territory</a> when I started writing some simple code for sending data into HDFS:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">package</span> <span class="nn">data.generator</span>
</span><span class='line'>
</span><span class='line'><span class="k">import</span> <span class="nn">com.twitter.elephantbird.mapreduce.io.ProtobufBlockWriter</span>
</span><span class='line'><span class="k">import</span> <span class="nn">data.generator.DataUtil.TestMessage</span>
</span><span class='line'><span class="k">import</span> <span class="nn">org.apache.hadoop.conf.Configuration</span>
</span><span class='line'><span class="k">import</span> <span class="nn">org.apache.hadoop.fs.</span><span class="o">{</span><span class="nc">FileSystem</span><span class="o">,</span> <span class="nc">Path</span><span class="o">}</span>
</span><span class='line'><span class="k">import</span> <span class="nn">org.apache.hadoop.io.compress</span>
</span><span class='line'>
</span><span class='line'><span class="k">import</span> <span class="nn">scala.compat.Platform</span>
</span><span class='line'><span class="k">import</span> <span class="nn">scalaz.EphemeralStream</span>
</span><span class='line'>
</span><span class='line'><span class="k">object</span> <span class="nc">DataWriterTest</span> <span class="o">{</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">def</span> <span class="n">main</span><span class="o">(</span><span class="n">args</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">String</span><span class="o">])</span> <span class="o">{</span>
</span><span class='line'>    <span class="n">writeSomeData</span><span class="o">(</span><span class="s">&quot;hdfs://192.168.50.25:50010&quot;</span><span class="o">,</span> <span class="mi">1000000</span><span class="o">,</span> <span class="s">&quot;/tmp/test.snappy&quot;</span><span class="o">)</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">def</span> <span class="n">writeSomeData</span><span class="o">(</span><span class="n">hdfsURI</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">numberOfMessages</span><span class="k">:</span> <span class="kt">Int</span><span class="o">,</span> <span class="n">destPath</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>    <span class="k">def</span> <span class="n">getSnappyWriter</span><span class="o">()</span><span class="k">:</span> <span class="kt">ProtobufBlockWriter</span><span class="o">[</span><span class="kt">TestMessage</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
</span><span class='line'>      <span class="k">val</span> <span class="n">conf</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Configuration</span><span class="o">()</span>
</span><span class='line'>      <span class="k">val</span> <span class="n">fs</span> <span class="k">=</span> <span class="nc">FileSystem</span><span class="o">.</span><span class="n">get</span><span class="o">(</span><span class="k">new</span> <span class="nc">Path</span><span class="o">(</span><span class="n">hdfsURI</span><span class="o">).</span><span class="n">toUri</span><span class="o">,</span> <span class="n">conf</span><span class="o">)</span>
</span><span class='line'>      <span class="k">val</span> <span class="n">outputStream</span> <span class="k">=</span> <span class="n">fs</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="k">new</span> <span class="nc">Path</span><span class="o">(</span><span class="n">destPath</span><span class="o">),</span> <span class="kc">true</span><span class="o">)</span>
</span><span class='line'>      <span class="k">val</span> <span class="n">codec</span> <span class="k">=</span> <span class="k">new</span> <span class="n">compress</span><span class="o">.</span><span class="nc">SnappyCodec</span><span class="o">()</span>
</span><span class='line'>      <span class="n">codec</span><span class="o">.</span><span class="n">setConf</span><span class="o">(</span><span class="n">conf</span><span class="o">);</span>
</span><span class='line'>      <span class="k">val</span> <span class="n">snappyOutputStream</span> <span class="k">=</span> <span class="n">codec</span><span class="o">.</span><span class="n">createOutputStream</span><span class="o">(</span><span class="n">outputStream</span><span class="o">)</span>
</span><span class='line'>      <span class="k">new</span> <span class="nc">ProtobufBlockWriter</span><span class="o">[</span><span class="kt">TestMessage</span><span class="o">](</span><span class="n">snappyOutputStream</span><span class="o">,</span> <span class="n">classOf</span><span class="o">[</span><span class="kt">TestMessage</span><span class="o">])</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'>    <span class="k">def</span> <span class="n">getMessage</span><span class="o">(</span><span class="n">messageId</span><span class="k">:</span> <span class="kt">Long</span><span class="o">)</span><span class="k">:</span> <span class="kt">TestMessage</span> <span class="o">=</span> <span class="nc">DataUtil</span><span class="o">.</span><span class="n">createRandomTestMessage</span><span class="o">(</span><span class="n">messageId</span><span class="o">);</span>
</span><span class='line'>    <span class="c1">// produces a lazy stream of messages</span>
</span><span class='line'>    <span class="k">def</span> <span class="n">getMessageStream</span><span class="o">(</span><span class="n">messageId</span><span class="k">:</span> <span class="kt">Long</span><span class="o">)</span><span class="k">:</span> <span class="kt">EphemeralStream</span><span class="o">[</span><span class="kt">TestMessage</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
</span><span class='line'>      <span class="k">val</span> <span class="n">messageStream</span><span class="k">:</span> <span class="kt">EphemeralStream</span><span class="o">[</span><span class="kt">TestMessage</span><span class="o">]</span> <span class="k">=</span> <span class="n">getMessage</span><span class="o">(</span><span class="n">messageId</span><span class="o">)</span> <span class="o">##::</span> <span class="n">getMessageStream</span><span class="o">(</span><span class="n">messageId</span> <span class="o">+</span> <span class="mi">1</span><span class="o">)</span>
</span><span class='line'>      <span class="k">return</span> <span class="n">messageStream</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">writer</span> <span class="k">=</span> <span class="n">getSnappyWriter</span><span class="o">()</span>
</span><span class='line'>    <span class="n">getMessageStream</span><span class="o">(</span><span class="mi">1</span><span class="o">).</span><span class="n">takeWhile</span><span class="o">(</span><span class="n">message</span> <span class="k">=&gt;</span> <span class="n">message</span><span class="o">.</span><span class="n">getMessageId</span> <span class="o">&lt;</span> <span class="n">numberOfMessages</span><span class="o">)</span>
</span><span class='line'>      <span class="o">.</span><span class="n">foreach</span><span class="o">(</span><span class="n">message</span> <span class="k">=&gt;</span> <span class="n">writer</span><span class="o">.</span><span class="n">write</span><span class="o">(</span><span class="n">message</span><span class="o">))</span>
</span><span class='line'>    <span class="n">writer</span><span class="o">.</span><span class="n">finish</span><span class="o">()</span>
</span><span class='line'>    <span class="n">writer</span><span class="o">.</span><span class="n">close</span><span class="o">()</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>As far as I could tell this pattern for writing was consistent with most of the tutorials I found via Google, the only new thing I added
in was the use of Twitter&rsquo;s <a href="https://github.com/kevinweil/elephant-bird/">elephantbird</a> library to write Snappy compressed Protocol Buffer data.
So I was surprised when I saw (and kept seeing) the following errors:</p>

<p>Client Errors:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>Exception in thread <span class="s2">&quot;main&quot;</span> java.io.IOException: Failed on <span class="nb">local </span>exception: java.io.EOFException; Host Details : <span class="nb">local </span>host is: <span class="s2">&quot;.local/192.168.1.2&quot;</span>; destination host is: <span class="s2">&quot;localhost.localdomain&quot;</span>:50010;
</span><span class='line'>  at org.apache.hadoop.net.NetUtils.wrapException<span class="o">(</span>NetUtils.java:764<span class="o">)</span>
</span><span class='line'>  at org.apache.hadoop.ipc.Client.call<span class="o">(</span>Client.java:1413<span class="o">)</span>
</span><span class='line'>  at org.apache.hadoop.ipc.Client.call<span class="o">(</span>Client.java:1362<span class="o">)</span>
</span><span class='line'>  at org.apache.hadoop.ipc.ProtobufRpcEngine<span class="nv">$Invoker</span>.invoke<span class="o">(</span>ProtobufRpcEngine.java:206<span class="o">)</span>
</span><span class='line'>  at com.sun.proxy.<span class="nv">$Proxy9</span>.create<span class="o">(</span>Unknown Source<span class="o">)</span>
</span><span class='line'>  at sun.reflect.NativeMethodAccessorImpl.invoke0<span class="o">(</span>Native Method<span class="o">)</span>
</span><span class='line'>  at sun.reflect.NativeMethodAccessorImpl.invoke<span class="o">(</span>NativeMethodAccessorImpl.java:57<span class="o">)</span>
</span><span class='line'>  at sun.reflect.DelegatingMethodAccessorImpl.invoke<span class="o">(</span>DelegatingMethodAccessorImpl.java:43<span class="o">)</span>
</span><span class='line'>  at java.lang.reflect.Method.invoke<span class="o">(</span>Method.java:606<span class="o">)</span>
</span><span class='line'>  at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod<span class="o">(</span>RetryInvocationHandler.java:186<span class="o">)</span>
</span><span class='line'>  at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke<span class="o">(</span>RetryInvocationHandler.java:102<span class="o">)</span>
</span><span class='line'>  at com.sun.proxy.<span class="nv">$Proxy9</span>.create<span class="o">(</span>Unknown Source<span class="o">)</span>
</span><span class='line'>  at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create<span class="o">(</span>ClientNamenodeProtocolTranslatorPB.java:258<span class="o">)</span>
</span><span class='line'>  at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate<span class="o">(</span>DFSOutputStream.java:1598<span class="o">)</span>
</span><span class='line'>  at org.apache.hadoop.hdfs.DFSClient.create<span class="o">(</span>DFSClient.java:1460<span class="o">)</span>
</span><span class='line'>  at org.apache.hadoop.hdfs.DFSClient.create<span class="o">(</span>DFSClient.java:1385<span class="o">)</span>
</span><span class='line'>  at org.apache.hadoop.hdfs.DistributedFileSystem<span class="nv">$6</span>.doCall<span class="o">(</span>DistributedFileSystem.java:394<span class="o">)</span>
</span><span class='line'>  at org.apache.hadoop.hdfs.DistributedFileSystem<span class="nv">$6</span>.doCall<span class="o">(</span>DistributedFileSystem.java:390<span class="o">)</span>
</span><span class='line'>  at org.apache.hadoop.fs.FileSystemLinkResolver.resolve<span class="o">(</span>FileSystemLinkResolver.java:81<span class="o">)</span>
</span><span class='line'>  at org.apache.hadoop.hdfs.DistributedFileSystem.create<span class="o">(</span>DistributedFileSystem.java:390<span class="o">)</span>
</span><span class='line'>  at org.apache.hadoop.hdfs.DistributedFileSystem.create<span class="o">(</span>DistributedFileSystem.java:334<span class="o">)</span>
</span><span class='line'>  at org.apache.hadoop.fs.FileSystem.create<span class="o">(</span>FileSystem.java:906<span class="o">)</span>
</span><span class='line'>  at org.apache.hadoop.fs.FileSystem.create<span class="o">(</span>FileSystem.java:887<span class="o">)</span>
</span><span class='line'>  at org.apache.hadoop.fs.FileSystem.create<span class="o">(</span>FileSystem.java:784<span class="o">)</span>
</span><span class='line'>  at data.generator.DataWriterTest<span class="nv">$.</span>getSnappyWriter<span class="nv">$1</span><span class="o">(</span>DataWriterTest.scala:23<span class="o">)</span>
</span><span class='line'>  at data.generator.DataWriterTest<span class="nv">$.</span>writeSomeData<span class="o">(</span>DataWriterTest.scala:35<span class="o">)</span>
</span><span class='line'>  at data.generator.DataWriterTest<span class="nv">$.</span>main<span class="o">(</span>DataWriterTest.scala:16<span class="o">)</span>
</span><span class='line'>  at data.generator.DataWriterTest.main<span class="o">(</span>DataWriterTest.scala<span class="o">)</span>
</span><span class='line'>  at sun.reflect.NativeMethodAccessorImpl.invoke0<span class="o">(</span>Native Method<span class="o">)</span>
</span><span class='line'>  at sun.reflect.NativeMethodAccessorImpl.invoke<span class="o">(</span>NativeMethodAccessorImpl.java:57<span class="o">)</span>
</span><span class='line'>  at sun.reflect.DelegatingMethodAccessorImpl.invoke<span class="o">(</span>DelegatingMethodAccessorImpl.java:43<span class="o">)</span>
</span><span class='line'>  at java.lang.reflect.Method.invoke<span class="o">(</span>Method.java:606<span class="o">)</span>
</span><span class='line'>  at com.intellij.rt.execution.application.AppMain.main<span class="o">(</span>AppMain.java:134<span class="o">)</span>
</span><span class='line'>Caused by: java.io.EOFException
</span><span class='line'>  at java.io.DataInputStream.readInt<span class="o">(</span>DataInputStream.java:392<span class="o">)</span>
</span><span class='line'>  at org.apache.hadoop.ipc.Client<span class="nv">$Connection</span>.receiveRpcResponse<span class="o">(</span>Client.java:1053<span class="o">)</span>
</span><span class='line'>  at org.apache.hadoop.ipc.Client<span class="nv">$Connection</span>.run<span class="o">(</span>Client.java:948<span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>Server Errors (hdfs datanode log):</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: localhost.localdomain:50010:DataXceiver error processing unknown operation  src: /192.168.50.2:56439 dest: /192.168.50.25:50010
</span><span class='line'>java.io.IOException: Version Mismatch <span class="o">(</span>Expected: 28, Received: 26738 <span class="o">)</span>
</span><span class='line'>  at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.readOp<span class="o">(</span>Receiver.java:57<span class="o">)</span>
</span><span class='line'>  at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run<span class="o">(</span>DataXceiver.java:206<span class="o">)</span>
</span><span class='line'>  at java.lang.Thread.run<span class="o">(</span>Thread.java:744<span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>After about 8 hours of lots of googling and ensuring all client and server jars were the same version my surprise turned to frustration. Especially since
the error messages were so vague.</p>

<p>Finally after a few circuits at the gym, I started from scratch and read through all the documentation I could find about typical data loading strategies for HDFS
(something I should have done to begin with). This led me to the realization that my client-server mental model was flawed within the HDFS context
since HDFS makes no assumption about where the data is being written from (in fact it seems to assume that the client is local to the cluster).
Some quick exploration of the <code>org.apache.hadoop.fs.FileSystem</code> class hierarchy showed that there are a variety of different ways for writing
to HDFS and only some of them are over TCP/IP. So with a little refactoring to use the <code>org.apache.hadoop.hdfs.web.WebHdfsFileSystem</code> implementation
my code works just fine:</p>

<p>Note the new <code>webhdfs://</code> protocol in the URI and the new port of <code>50070</code>. There seems to be a tight coupling of protocol to <code>FileSystem</code>
implementation as well as port mapping, but I have not found great documentation yet as to what this coupling is.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'> <span class="k">package</span> <span class="nn">data.generator</span>
</span><span class='line'>
</span><span class='line'> <span class="k">import</span> <span class="nn">java.net.URI</span>
</span><span class='line'>
</span><span class='line'> <span class="k">import</span> <span class="nn">com.twitter.elephantbird.mapreduce.io.ProtobufBlockWriter</span>
</span><span class='line'> <span class="k">import</span> <span class="nn">data.generator.DataUtil.TestMessage</span>
</span><span class='line'> <span class="k">import</span> <span class="nn">org.apache.hadoop.conf.Configuration</span>
</span><span class='line'> <span class="k">import</span> <span class="nn">org.apache.hadoop.fs.</span><span class="o">{</span><span class="nc">FileSystem</span><span class="o">,</span> <span class="nc">Path</span><span class="o">}</span>
</span><span class='line'> <span class="k">import</span> <span class="nn">org.apache.hadoop.hdfs.web.WebHdfsFileSystem</span>
</span><span class='line'> <span class="k">import</span> <span class="nn">org.apache.hadoop.io.compress</span>
</span><span class='line'>
</span><span class='line'> <span class="k">import</span> <span class="nn">scala.compat.Platform</span>
</span><span class='line'> <span class="k">import</span> <span class="nn">scalaz.EphemeralStream</span>
</span><span class='line'>
</span><span class='line'> <span class="k">object</span> <span class="nc">DataWriterTest</span> <span class="o">{</span>
</span><span class='line'>
</span><span class='line'>   <span class="k">def</span> <span class="n">main</span><span class="o">(</span><span class="n">args</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">String</span><span class="o">])</span> <span class="o">{</span>
</span><span class='line'>     <span class="n">writeSomeData</span><span class="o">(</span><span class="s">&quot;webhdfs://192.168.50.25:50070&quot;</span><span class="o">,</span> <span class="mi">1000000</span><span class="o">,</span> <span class="s">&quot;/tmp/test2.snappy&quot;</span><span class="o">)</span>
</span><span class='line'>   <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>   <span class="k">def</span> <span class="n">writeSomeData</span><span class="o">(</span><span class="n">hdfsURI</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">numberOfMessages</span><span class="k">:</span> <span class="kt">Int</span><span class="o">,</span> <span class="n">destPath</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>     <span class="k">def</span> <span class="n">getSnappyWriter</span><span class="o">()</span><span class="k">:</span> <span class="kt">ProtobufBlockWriter</span><span class="o">[</span><span class="kt">TestMessage</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
</span><span class='line'>       <span class="k">val</span> <span class="n">conf</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Configuration</span><span class="o">()</span>
</span><span class='line'>       <span class="k">val</span> <span class="n">fs</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">WebHdfsFileSystem</span><span class="o">();</span>
</span><span class='line'>       <span class="n">fs</span><span class="o">.</span><span class="n">initialize</span><span class="o">(</span><span class="k">new</span> <span class="nc">Path</span><span class="o">(</span><span class="n">hdfsURI</span><span class="o">).</span><span class="n">toUri</span><span class="o">,</span> <span class="n">conf</span><span class="o">)</span>
</span><span class='line'>       <span class="k">val</span> <span class="n">outputStream</span> <span class="k">=</span> <span class="n">fs</span><span class="o">.</span><span class="n">create</span><span class="o">(</span><span class="k">new</span> <span class="nc">Path</span><span class="o">(</span><span class="n">destPath</span><span class="o">),</span> <span class="kc">true</span><span class="o">)</span>
</span><span class='line'>       <span class="k">val</span> <span class="n">codec</span> <span class="k">=</span> <span class="k">new</span> <span class="n">compress</span><span class="o">.</span><span class="nc">SnappyCodec</span><span class="o">()</span>
</span><span class='line'>       <span class="n">codec</span><span class="o">.</span><span class="n">setConf</span><span class="o">(</span><span class="n">conf</span><span class="o">);</span>
</span><span class='line'>       <span class="k">val</span> <span class="n">snappyOutputStream</span> <span class="k">=</span> <span class="n">codec</span><span class="o">.</span><span class="n">createOutputStream</span><span class="o">(</span><span class="n">outputStream</span><span class="o">)</span>
</span><span class='line'>       <span class="k">new</span> <span class="nc">ProtobufBlockWriter</span><span class="o">[</span><span class="kt">TestMessage</span><span class="o">](</span><span class="n">snappyOutputStream</span><span class="o">,</span> <span class="n">classOf</span><span class="o">[</span><span class="kt">TestMessage</span><span class="o">])</span>
</span><span class='line'>     <span class="o">}</span>
</span><span class='line'>     <span class="k">def</span> <span class="n">getMessage</span><span class="o">(</span><span class="n">messageId</span><span class="k">:</span> <span class="kt">Long</span><span class="o">)</span><span class="k">:</span> <span class="kt">TestMessage</span> <span class="o">=</span> <span class="nc">DataUtil</span><span class="o">.</span><span class="n">createRandomTestMessage</span><span class="o">(</span><span class="n">messageId</span><span class="o">);</span>
</span><span class='line'>     <span class="c1">// produces a lazy stream of messages</span>
</span><span class='line'>     <span class="k">def</span> <span class="n">getMessageStream</span><span class="o">(</span><span class="n">messageId</span><span class="k">:</span> <span class="kt">Long</span><span class="o">)</span><span class="k">:</span> <span class="kt">EphemeralStream</span><span class="o">[</span><span class="kt">TestMessage</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
</span><span class='line'>       <span class="k">val</span> <span class="n">messageStream</span><span class="k">:</span> <span class="kt">EphemeralStream</span><span class="o">[</span><span class="kt">TestMessage</span><span class="o">]</span> <span class="k">=</span> <span class="n">getMessage</span><span class="o">(</span><span class="n">messageId</span><span class="o">)</span> <span class="o">##::</span> <span class="n">getMessageStream</span><span class="o">(</span><span class="n">messageId</span> <span class="o">+</span> <span class="mi">1</span><span class="o">)</span>
</span><span class='line'>       <span class="k">return</span> <span class="n">messageStream</span>
</span><span class='line'>     <span class="o">}</span>
</span><span class='line'>     <span class="k">val</span> <span class="n">writer</span> <span class="k">=</span> <span class="n">getSnappyWriter</span><span class="o">()</span>
</span><span class='line'>     <span class="n">getMessageStream</span><span class="o">(</span><span class="mi">1</span><span class="o">).</span><span class="n">takeWhile</span><span class="o">(</span><span class="n">message</span> <span class="k">=&gt;</span> <span class="n">message</span><span class="o">.</span><span class="n">getMessageId</span> <span class="o">&lt;</span> <span class="n">numberOfMessages</span><span class="o">)</span>
</span><span class='line'>       <span class="o">.</span><span class="n">foreach</span><span class="o">(</span><span class="n">message</span> <span class="k">=&gt;</span> <span class="n">writer</span><span class="o">.</span><span class="n">write</span><span class="o">(</span><span class="n">message</span><span class="o">))</span>
</span><span class='line'>     <span class="n">writer</span><span class="o">.</span><span class="n">finish</span><span class="o">()</span>
</span><span class='line'>     <span class="n">writer</span><span class="o">.</span><span class="n">close</span><span class="o">()</span>
</span><span class='line'>   <span class="o">}</span>
</span><span class='line'> <span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p> File in hdfs:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>hdfs dfs -ls -h /tmp
</span><span class='line'>Found 1 item
</span><span class='line'>-rw-r--r--   3 pcichonski supergroup    215.9 M 2014-07-19 08:44 /tmp/test2.snappy
</span></code></pre></td></tr></table></div></figure>


<p>I&rsquo;m still not sure this is the write method for writing large amounts of data to HDFS, but more dots are starting to connect in my head
about how the component parts of the ecosystem fit together. Lots more to learn though.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Meetup Talks]]></title>
    <link href="http://paulcichonski.com/blog/2014/02/01/recent-talks/"/>
    <updated>2014-02-01T11:00:00-05:00</updated>
    <id>http://paulcichonski.com/blog/2014/02/01/recent-talks</id>
    <content type="html"><![CDATA[<p>I had the opportunity to speak at two Meetups in January on the work I&rsquo;ve been doing for the past few months at <a href="http://www.lithium.com/">Lithium</a>. The first talk was at a new Meetup that Lithium started called <a href="http://www.meetup.com/CloudOps/">Cloudops</a> that is oriented towards engineers working devops roles in cloud environments. My talk was a short 15 minute talk (<a href="http://www.slideshare.net/PaulCichonski/cichonski-cloud-ops20140128">slides here</a>) covering strategies for building fault tolerant systems in cloud environments and my thoughts on how to monitor those systems. My favorite part of the talk was introducing <a href="http://en.wikipedia.org/wiki/OODA_loop">Boyd&rsquo;s OODA loop</a> as a process model for devops work. I&rsquo;ve dealt a lot with the OODA loop in my past role at <a href="http://www.nist.gov/">NIST</a> when we were trying to improve the process for <a href="http://csrc.nist.gov/publications/nistpubs/800-61rev2/SP800-61rev2.pdf">IT security incident handling</a> in the industry. I still think OODA is one of the better process models out there since it is abstract enough to remain relevant across many disciplines while still offering value in each individual domain that binds to it.</p>

<p>My second talk was at the <a href="http://www.meetup.com/CassandraSF/">Datastax Cassandra SF Meetup</a> hosted at <a href="http://disqus.com/">Disqus</a>. This talk (<a href="http://www.slideshare.net/PaulCichonski/cassandra-at-lithium">slides here</a>) was a bit more low-level and focused on how we have been using Cassandra at Lithium for the past six months as we move to a more service-oriented architecture internally. This talk was primarily focused on our use case, data model, and all of the issues we dealt with getting Cassandra into production. I also covered the strategy we used for migrating data from MySQL to Cassandra with zero downtime. Our migration strategy was heavily influenced by a Netflix <a href="http://techblog.netflix.com/2013/02/netflix-queue-data-migration-for-high.html">blog post</a> covering a migration from SimpleDB to Cassandra.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Setting Up Octopress on a new Machine]]></title>
    <link href="http://paulcichonski.com/blog/2013/11/10/setting-up-octopress-on-a-new-machine/"/>
    <updated>2013-11-10T20:46:00-05:00</updated>
    <id>http://paulcichonski.com/blog/2013/11/10/setting-up-octopress-on-a-new-machine</id>
    <content type="html"><![CDATA[<p>As soon as I got this blog up and running, the first thing I did was to completely screw up my <a href="http://octopress.org/">Octopress</a> install (apparently I did need all those files I deleted), thus rendering the entire site useless. As with anything &ldquo;tinkering&rdquo; related, this is fairly normal so it is also fairly normal to rebuild from scratch. Luckily, smart people have <a href="http://blog.zerosharp.com/clone-your-octopress-to-blog-from-two-places/">already figured out</a> how to do this.</p>

<p>The following steps outline how to setup a fresh Octopress install that connects to an existing <a href="http://pages.github.com/">Github Pages</a> repository (this builds on the zerosharp post with some updates based on recent changes in Octopress). <strong>These steps assume that the Github repository is fully up to date with all latest changes</strong></p>

<p>First you need to make sure that your <code>source</code> directory actually contains the <code>source/_posts</code> and the <code>stylesheets</code> folder. You also need to make sure .gitignore is not ignoring any of these (if there is a reason these should not be committed please let me know, I could not think of any).</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>## This needs to happen on your first machine, for some reason they are ignored by default.
</span><span class='line'>cd source/
</span><span class='line'>git add _posts/ 
</span><span class='line'>git add stylesheets
</span><span class='line'>git commit -m "adding posts and stylesheets dir"
</span><span class='line'>git push origin source</span></code></pre></td></tr></table></div></figure>


<p>The remainder of the steps happen on your second machine. First clone the <code>source</code> branch</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>git clone -b source git@github.com:username/username.github.io.git octopress
</span><span class='line'>cd octopress</span></code></pre></td></tr></table></div></figure>


<p>Next, install Octopress</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>gem install bundler
</span><span class='line'>rbenv rehash    # If you use rbenv, rehash to be able to run the bundle command
</span><span class='line'>bundle install
</span><span class='line'>rake setup_github_pages</span></code></pre></td></tr></table></div></figure>


<p>The last command deleted the <code>_deploy</code> directory and re-added it. We don&rsquo;t want this because we want the latest changes from <code>_deploy</code> so we don&rsquo;t run into any nasty <code>[rejected]        master -&gt; master (non-fast-forward)</code> git errors because of an out-of-date branch.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>rm -rf _deploy
</span><span class='line'>git clone git@github.com:username/username.github.io.git _deploy</span></code></pre></td></tr></table></div></figure>


<p>Octopress should now be setup, and the <code>source</code> dir should contain your up-to-date markdown. To test things out make a change to a post (or make a new post) then regenerate and deploy.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>rake generate
</span><span class='line'>rake deploy</span></code></pre></td></tr></table></div></figure>


<p>Your new changes should appear on your site. The only downside of this approach is that when you go back to your original machine and try to deploy, git will yell at you (i.e., non-fast-forward error) because the <code>_deploy</code> dir from that machine is now out of date. The best way to fix this is to remove it (see above) and re-clone it (see above). The other option is to edit the <code>octopress/RakeFile</code> and change the line: <code>system "git push origin #{deploy_branch}"</code> to <code>system "git push origin +#{deploy_branch}"</code> to force the deployment despite version mismatches (<strong>be sure to undo this change immediately after</strong>).</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Building this Blog with Octopress]]></title>
    <link href="http://paulcichonski.com/blog/2013/11/10/building-this-blog-with-octopress/"/>
    <updated>2013-11-10T15:14:00-05:00</updated>
    <id>http://paulcichonski.com/blog/2013/11/10/building-this-blog-with-octopress</id>
    <content type="html"><![CDATA[<p>I just setup this blog using <a href="http://octopress.org/">Octopress</a> as the page generation engine and <a href="http://pages.github.com/">Github Pages</a> to <strong>freely</strong> host the content. In total, it took me about four hours to get from start to first blog post, and that was mainly because my ruby environment on my dev machine was fairly messed up from mucking around six months ago.</p>

<p>This initial post is both a how-to for setting up a blog with Octopress/Github and quick cheat-sheet so I don&rsquo;t forget how I did things.</p>

<h2>Setup</h2>

<p>The <a href="http://octopress.org/docs/setup/">Octopress setup docs</a> are incredibly helpful, so I&rsquo;m not going to duplicate content explaining what everything means. Assuming ruby is correctly installed the setup commands are as follows:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>## 1. Create personal github repo named "username.github.io", mine is "paulcichonski.github.io"
</span><span class='line'>## 2. Clone Octopress repo locally and setup directory structure
</span><span class='line'>git clone git://github.com/imathis/octopress.git octopress
</span><span class='line'>cd octopress
</span><span class='line'>rake install
</span><span class='line'>## 3. connect your local install with your git repo (see Octopress docs for more details: http://octopress.org/docs/deploying/github/)
</span><span class='line'>rake setup_github_pages</span></code></pre></td></tr></table></div></figure>


<p>The above commands will leave your &lsquo;/octopress&rsquo; dir in a state where you are ready to begin blogging. You can think of the &lsquo;/octopress&rsquo; dir as a container for all your blog content as well as the library for all the commands you need to push content to Github.</p>

<h2>Important Octopress Files and Directories</h2>

<p>The following files and directories comprise the essential building blocks for an Octopress site:</p>

<ul>
<li><strong>/octopress/_config.yml</strong>: Holds all the configuration for the site, Octopress uses this when generating your static HTML pages from markdown.</li>
<li><strong>/octopress/source/</strong> &ndash; This is the directory that includes all the content you actually edit, it syncs with the &lsquo;source&rsquo; branch of your github repository. Remember to always commit any changes made in this directory to your &lsquo;source&rsquo; branch. Running &ldquo;rake generate&rdquo; from the &lsquo;/octopress&rsquo; dir level will take the files in &lsquo;source&rsquo;, parse them in combination with your &lsquo;_config.yml&rsquo; file and generate static html content into the &lsquo;_deploy&rsquo; dir.</li>
<li><strong>/octopress/_deploy</strong> &ndash; This is the directory that Octopress will dynamically generate, it contains your actual website static HTML that people see. When you run &ldquo;rake deploy&rdquo; Octopress handles pushing all content from &lsquo;_deploy&rsquo; to the &lsquo;master&rsquo; branch of your github repo (i.e., the branch responsible for serving content).</li>
</ul>


<h2>Important Octopress Commands</h2>

<p>The following commands are the most useful for doing basic things with Octopress</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>## generates static html by parsing markdown in 'source' directory, using '\_config.yml' for configuration parameters
</span><span class='line'>rake generate
</span><span class='line'>## deploys all content in '\_deploy' to the 'master' branch on your github repo 
</span><span class='line'>rake deploy 
</span><span class='line'>## binds a webserver to localhost:4000 that serves pages from '\_deploy'; watches for changes in 'source' and auto-generates all changes into '\_deploy'. Use this for local development.
</span><span class='line'>rake preview </span></code></pre></td></tr></table></div></figure>


<p>That is it for now, still need to document how to perform development from multiple machines and how to rebuild your local development workstation if something goes wrong.</p>
]]></content>
  </entry>
  
</feed>
